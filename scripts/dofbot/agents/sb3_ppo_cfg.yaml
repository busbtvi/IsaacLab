# Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).
# All rights reserved.
#
# SPDX-License-Identifier: BSD-3-Clause

# Reference: https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml#L32
seed: 42

# 1. num_env * n_step 만큼 데이터를 모은뒤, 임시 데이터 버퍼에 넣고
# 2. batch_size 만큼 버퍼에서 데이터를 뽑아서 신경망을 학습
# 3. 2번 과정을 n_epochs 만큼 반복
# 4. 1번에서 모은 데이터를 버림
# 5. (num_env * n_step) 덩어리씩 모은 데이터가 n_timesteps가 될 때 까지 반복

n_timesteps: !!float 5e6

# policy: "MlpPolicy"
# policy_kwargs:
#   activation_fn: "nn.ELU"
#   net_arch: [64, 128, 64]
#   squash_output: False

policy: "MultiInputPolicy"
policy_kwargs:
  # squash_output: true # 정책 출력은 tanh로 제한
  normalize_images: true                # uint8 → 0~1 자동 정규화
  net_arch: {pi: [128, 128], vf: [128, 128]}
use_sde: true                         # squash_output 쓰려면 필수

n_steps: 128
batch_size: 256
gae_lambda: 0.95
gamma: 0.99
n_epochs: 20
ent_coef: 0.03
learning_rate: !!float 3e-4
clip_range: !!float 0.3
vf_coef: 1.0
max_grad_norm: 1.0
device: "cuda:0"
